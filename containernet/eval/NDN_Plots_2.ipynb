{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d7023e07254a8798dd2a7a90830e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "import matplotlib as plt\n",
    "import sys\n",
    "sys.path.append('../../plotting')\n",
    "from plotlib import * \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import glob\n",
    "from math import sqrt\n",
    "SPINE_COLOR = 'gray'\n",
    "PATH = './../NDN/results/client2/2017112709:25:46_log'\n",
    "import os\n",
    "script = \"./../NDN/Extract_KPIs.sh\"\n",
    "data = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trace_file_url(trace_file_url):\n",
    "    colnames = ['Timestamp','Increasingtime','GPS_1','GPS_2', 'bytes', 'elapsed_ms']\n",
    "    data = pd.read_csv(trace_file_url, names=colnames, delim_whitespace=True)\n",
    "    data['bitrate'] = data.bytes * 8 /  (data.elapsed_ms * 1000 )# mbit/s\n",
    "    data['Increasingtime'] = (data['Increasingtime'] - data['Increasingtime'][0]) / 1000 - 288\n",
    "    data.Timestamp = pd.to_datetime(data.Timestamp)\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Video Segment/Sampled throughput\n",
    "def sampletroughput(PATH, kind='other'):\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        path = os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)),  \"throughput\")\n",
    "        print(path)\n",
    "        df = pd.read_csv(path, delim_whitespace=True ,names = ['seconds_offset', 'throughput'])\n",
    "        df.throughput = df.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        title=f\n",
    "\n",
    "        profile = read_trace_file_url('./report.2010-09-28_1407CEST.log.txt')\n",
    "        sec=profile.Timestamp\n",
    "        bw=profile.bitrate\n",
    "        if kind == 'cdf':\n",
    "            fig = df.plot(\"throughput\", kind='hist',  bins=200, normed=1, histtype='step',\n",
    "                           cumulative=True)\n",
    "            fig.set_ylabel('Density')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "            #fig.set_xlim(0, 5)\n",
    "        else:\n",
    "            fig = df.plot(x=\"seconds_offset\", y=\"throughput\", kind='scatter', s=0.01)\n",
    "            fig.set_xlabel('Playback time (seconds)')\n",
    "            lines = fig.set_ylabel('Mbit/s')\n",
    "\n",
    "        fig.plot(sec, bw, 'r--')\n",
    "\n",
    "        fig.set_title(os.path.dirname(f))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{0}_throughput{1}\".format(f, \".pdf\"))\n",
    "\n",
    "#sampletroughput(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NDN Chunk throughput\n",
    "\n",
    "def ndnChunkTroghput(PATH, kind='dots'):\n",
    "    N = 5\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        print(f)\n",
    "        #global df\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        title=f\n",
    "\n",
    "        #profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "        #sec=profile.seconds_offset\n",
    "        #bw=profile.bandwidth\n",
    "\n",
    "        #x=df.seconds_offset\n",
    "        #y=df.chunkThroughput\n",
    "        #plt.hexbin(x, y, gridsize=(600,1000), yscale='log', mincnt = 1)\n",
    "        #plt.tight_layout()\n",
    "        #plt.savefig(f+\"_kde_grid_logy.pdf\")\n",
    "        if kind == 'scatter':\n",
    "            fig = df.plot(x=\"seconds_offset\" , y=\"chunkThroughput\", logy=False, kind='scatter', marker='x', s=0.05)\n",
    "            fig.set_xlabel('Playback time (seconds)')\n",
    "            fig.set_ylim(0,6)\n",
    "            fig.set_xlim(0,200)\n",
    "            fig.set_ylabel('Mbit/s')\n",
    "        elif kind == 'hist':\n",
    "            fig = df.plot(x=\"seconds_offset\" , y=\"chunkThroughput\", kind='hist', bins=50)\n",
    "            fig.set_ylabel('???')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "        elif kind == 'kde':\n",
    "            fig = df.plot(\"chunkThroughput\", kind='kde')\n",
    "            fig.set_ylabel('Density')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "            fig.set_xlim(0, 100)\n",
    "        elif kind == 'cdf':\n",
    "            fig = df.plot(\"seconds_offset\", kind='hist',  bins=200, normed=1, histtype='step',\n",
    "                           cumulative=True)\n",
    "            fig.set_ylabel('Density')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "            fig.set_xlim(0, 10)\n",
    "            \n",
    "        #profile = read_trace_file_url('./ndn/report.2010-09-28_1407CEST.log.txt')\n",
    "        #sec=profile['Increasingtime']\n",
    "        #bw=profile.bitrate\n",
    "        #profile\n",
    "        #fig.plot(sec, bw, colors.mpl_colors[0])\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        fig.legend({'NDN-Chunk based measurment', 'Bandwidth trace'})\n",
    "\n",
    "\n",
    "\n",
    "        #data.update({os.path.dirname(f) : df})\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(\"{0}_scatter_natural_logy-{1}{2}\".format(f,os.path.dirname(f).split('/')[2], \".pdf\"))\n",
    "        \n",
    "        \n",
    "#NDN Chunk throughput\n",
    "\n",
    "def ndnChunkTroghputQuality(PATH):\n",
    "    N = 5\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        print(f)\n",
    "        #global df\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        title=f\n",
    "\n",
    "        #profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "        #sec=profile.seconds_offset\n",
    "        #bw=profile.bandwidth\n",
    "\n",
    "        #x=df.seconds_offset\n",
    "        #y=df.chunkThroughput\n",
    "        #plt.hexbin(x, y, gridsize=(600,1000), yscale='log', mincnt = 1)\n",
    "        #plt.tight_layout()\n",
    "        #plt.savefig(f+\"_kde_grid_logy.pdf\")\n",
    "        fig = df.plot(x=\"seconds_offset\" , y=\"chunkThroughput\", logy=False, label='NDN-Chunk Troughput', kind='scatter', c='0.4', marker='x', s=0.08)\n",
    "        fig.set_xlabel('Playback time (seconds)')\n",
    "        fig.set_ylim(0,6)\n",
    "        fig.set_xlim(0,200)\n",
    "        fig.set_ylabel('Mbit/s')\n",
    "            \n",
    "        profile = read_trace_file_url('./ndn/report.2010-09-28_1407CEST.log.txt')\n",
    "        sec=profile['Increasingtime']\n",
    "        bw=profile.bitrate\n",
    "        profile\n",
    "        bw_plot = fig.plot(sec, bw, label='Bandwidth Trace')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"quality\") , delim_whitespace=True, \n",
    "                         names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "\n",
    "        df.videobitrate = df.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        df.realbitrate = df.realbitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "\n",
    "        bitrate_plot = fig.plot(df.seconds_offset, df.videobitrate, 'r', label='Video Bitrate')\n",
    "        \n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        #fig.legend([bw_plot, bitrate_plot], ['Video Bitrate',  'Bandwidth trace'])\n",
    "        handles, labels = fig.get_legend_handles_labels()\n",
    "        # sort both labels and handles by labels\n",
    "        labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "        fig.legend(handles, labels)\n",
    "        fig.legend(handles, labels, ncol=3,  loc='upper center', frameon=True, mode=\"expand\")\n",
    "        #data.update({os.path.dirname(f) : df})\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(\"{0}_scatter_natural_logy-{1}{2}\".format(f,os.path.dirname(f).split('/')[2].strip('.'), \".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qualityPlot(PATH):\n",
    "    #Quality levels\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"quality\") , delim_whitespace=True, \n",
    "                         names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "        title=f\n",
    "        df.videobitrate = df.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        df.realbitrate = df.realbitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "        #profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "        #sec=profile.seconds_offset\n",
    "        #bw=profile.bandwidth\n",
    "\n",
    "        fig = df.plot(x=\"seconds_offset\", y=\"realbitrate\", )\n",
    "\n",
    "       # fig.plot([1, 600], [1.03, 1.03], 'y:') \n",
    "       # fig.plot([1, 600], [1.24, 1.24], 'y:')\n",
    "       # fig.plot([1, 600], [1.55, 1.55], 'y:')\n",
    "       # fig.plot([1, 600], [2.13, 2.13], 'y:')\n",
    "       # fig.plot([1, 600], [2.48, 2.48], 'y:')\n",
    "       # fig.plot([1, 600], [3.08, 3.08], 'y:')\n",
    "       # fig.plot([1, 600], [3.53, 3.53], 'y:')\n",
    "       # fig.plot([1, 600], [3.84, 3.84], 'y:')\n",
    "       # fig.plot([1, 600], [4.22, 4.22], 'y:')\n",
    "\n",
    "        br = fig.plot(df.seconds_offset, df.videobitrate, 'r:', label='Selected Adaptation Bitrate')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"bufferlevel\") , delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "        df.bufferlevel = df.bufferlevel.apply(lambda x: x * 1.00e+2) # in Percentage\n",
    "        #title=f\n",
    "        bl = fig.plot(df.seconds_offset, df.bufferlevel, 'k--', label='Real Segment Bitrate')\n",
    "\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        #fig.plot(sec, bw, 'k--')\n",
    "\n",
    "        print(df.videobitrate.mean())\n",
    "\n",
    "        fig.set_xlabel('Playback time (seconds)')\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        handles, labels = fig.get_legend_handles_labels()\n",
    "        # sort both labels and handles by labels\n",
    "        labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "        fig.legend(handles, labels, bbox_to_anchor=(0., 1.02, 1., 1.102), loc=1, ncol=1, mode=\"expand\", borderaxespad=0.)\n",
    "        #fig.legend([br, bl], ['Real Segment Bitrate', 'Selected Adaptation Bitrate'])\n",
    "        #, 'Buffer fill level (percentage)'})\n",
    "\n",
    "        lines = fig.set_ylabel('Video quality (Mbit/s)')\n",
    "        #plt.tight_layout()\n",
    "        #plt.savefig(\"{0}_quality-{1}{2}\".format(f,os.path.dirname(f).split('/')[2].strip('.'), \".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bufferPlot(PATH):\n",
    "    #Buffer fill level\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"bufferlevel\") , delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "        df.bufferlevel = df.bufferlevel.apply(lambda x: x * 1.00e+2) # in Percentage\n",
    "        title=f\n",
    "        fig = df.plot(x=\"seconds_offset\", y=\"bufferlevel\", )\n",
    "        fig.set_xlabel('Playback time (seconds)')\n",
    "        lines = fig.set_ylabel('Buffer fill level (percentage)')\n",
    "        plt.tight_layout()\n",
    "        fig.legend({})\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "\n",
    "        #plt.savefig(\"{0}_bufferlevel-{1}{2}\".format(f,os.path.dirname(f).split('/')[2].strip('.'), \".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #ax.set_ylabel('Mbit/s')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "        profile = read_trace_file_url('./ndn/report.2010-09-28_1407CEST.log.txt')\n",
    "        sec=profile['Increasingtime']\n",
    "        bw=profile.bitrate\n",
    "        profile\n",
    "        bw_plot = ax.plot(sec, bw, label='Bandwidth Trace')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"quality\") , delim_whitespace=True, \n",
    "                         names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "\n",
    "        df.videobitrate = df.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        df.realbitrate = df.realbitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "\n",
    "        bitrate_plot = ax.plot(df.seconds_offset, df.videobitrate, 'r', label='Video Bitrate')\n",
    "        \n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        #fig.legend([bw_plot, bitrate_plot], ['Video Bitrate',  'Bandwidth trace'])\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        # sort both labels and handles by labels\n",
    "        labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "        fig.legend(handles, labels)\n",
    "        fig.legend(handles, labels, ncol=3,  loc='upper center', frameon=True, mode=\"expand\")\n",
    "        #data.update({os.path.dirname(f) : df})\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(\"{0}_scatter_natural_logy-{1}{2}\".format(f,os.path.dirname(f).split('/')[2].strip('.'), \".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7925845b05a24eed9c04cae423472072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/client1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py:677: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/client2\n",
      "./results/client1\n",
      "./results/client2\n",
      "./results/client1\n",
      "./results/client2\n",
      "./gfx/ndn/ndn-scatter-segments-combined.pdf\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def ndnChunkTroghputQuality2(PATH, fig, ax):\n",
    "    N = 5\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        #fig, ax = plt.subplots(1,1)\n",
    "        format_axes(ax)\n",
    "        #global df\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        df.columns = map(lambda x: re.sub('_', '', x), df.columns)\n",
    "        #df['subject'] = 0\n",
    "        df = df.sample(frac=0.5)\n",
    "        title=f\n",
    "        #display(df.head())\n",
    "        ax.scatter(df[\"secondsoffset\"], df[\"chunkThroughput\"], marker='x', s=0.1, color=Accent_5.mpl_colors[1])\n",
    "        #sns.tsplot(data=df, unit='subject', interpolate=True, ci=[68, 95], time=\"secondsoffset\", value=\"chunkThroughput\")\n",
    "        ax.set_xlabel('Playback time (seconds)')\n",
    "        ax.set_ylabel('Video quality (Mbit/s)')\n",
    "        ax.set_ylim(0,6)\n",
    "        ax.set_xlim(0,200)\n",
    "        profile = read_trace_file_url('./ndn/report.2010-09-28_1407CEST.log.txt')\n",
    "        sec=profile['Increasingtime']\n",
    "        bw=profile.bitrate\n",
    "        profile\n",
    "        bw_plot = ax.plot(sec, bw, label='Bandwidth Trace')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"quality\") , delim_whitespace=True, \n",
    "                         names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "\n",
    "        df.videobitrate = df.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        df.realbitrate = df.realbitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        bitrate_plot = ax.plot(df.seconds_offset, df.videobitrate, 'r', label='Video Bitrate')\n",
    "        fig.tight_layout()\n",
    "        \n",
    "compPaths = [\n",
    "            ('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "#             ('Extended Panda', '2017.12.22-14:08-psequential_log'),\n",
    "             ('Extended Panda', '2017.12.21-09:04-psequential_log')]\n",
    "\n",
    "size = setupfiguresthin()\n",
    "fig, axes = plt.subplots(3,2)\n",
    "fig.set_size_inches(size[0], size[1]*3)\n",
    "j = 0\n",
    "for player in compPaths:\n",
    "    for i in range(1,3):\n",
    "        list_of_files = glob.glob('./results/client{0}/{1}'.format(i, player[1])) # * means all if need specific format then *.csv\n",
    "        latest_file = sorted(list_of_files, key=os.path.getctime)[0]\n",
    "        setupfigures80()\n",
    "        axes[j][i-1].set_title('{}, Player {}'.format(player[0], i))\n",
    "        ndnChunkTroghputQuality2(latest_file, fig, axes[j][i-1])\n",
    "        #qualityPlot(PATH)\n",
    "        #bufferPlot(PATH)\n",
    "    j = j + 1\n",
    "\n",
    "axes[0][0].legend(bbox_to_anchor=(0., 1.2, 2.2, .102), loc=3,\n",
    "               ncol=4, mode=\"expand\", borderaxespad=0)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.savefig(getFilename('ndn-scatter-segments-combined', 'ndn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#gOut/gIn and Chunk Throughput\n",
    "for f in glob.iglob('./*10-*/**/chunkThroughputRttQuotient', recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "    df = pd.read_csv(f, delim_whitespace=True, names = ['seconds_offset', 'rtt', 'quotient', 'chunkThroughput'])\n",
    "\n",
    "    \n",
    "    #df['movingavgTP'] = pd.rolling_mean(df.chunkThroughput, 100)\n",
    "    #df['movingavgQ'] = pd.rolling_mean(df.quotient, 100)\n",
    "    #fig = df.plot.scatter(x=\"movingavgTP\", y=\"movingavgQ\", s=0.001)\n",
    "    fig = df.plot.scatter(x=\"chunkThroughput\", y=\"quotient\", s=0.001)\n",
    "    \n",
    "    #fig.set_xscale('log')\n",
    "    #fig.set_yscale('log')\n",
    "    fig.set_xbound(0,10)\n",
    "    fig.set_ybound(0,3)\n",
    "    \n",
    "    fig.set_xlabel('Throughput (Mbit/s)')\n",
    "    fig.set_ylabel('gOut/gIn')\n",
    "    plt.tight_layout()\n",
    "    f = f[:-26]\n",
    "    plt.savefig(f+\"gOutgIn2chunkThroughput_natural_limxlimy3.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RTT and Chunk Throughput\n",
    "for f in glob.iglob('./*10-*/**/chunkThroughputRttQuotient', recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "    df = pd.read_csv(f, delim_whitespace=True, names = ['seconds_offset', 'rtt', 'quotient', 'chunkThroughput'])\n",
    "    df.rtt = df.rtt.apply(lambda x: x * 1.00e-3) # in ms\n",
    "    \n",
    "    #df['movingavgTP'] = pd.rolling_mean(df.chunkThroughput, 100)\n",
    "    #df['movingavgRTT'] = pd.rolling_mean(df.rtt, 100)\n",
    "    #fig = df.plot.scatter(x=\"movingavgTP\", y=\"movingavgRTT\", s=0.001)\n",
    "    fig = df.plot.scatter(x=\"chunkThroughput\", y=\"rtt\", s=0.001)\n",
    "    \n",
    "    #fig.set_xscale('log')\n",
    "    #fig.set_yscale('log')\n",
    "    fig.set_xbound(0,10)\n",
    "    \n",
    "    fig.set_xlabel('Throughput (Mbit/s)')\n",
    "    fig.set_ylabel('RTT (ms)')\n",
    "    plt.tight_layout()\n",
    "    f = f[:-26]\n",
    "    plt.savefig(f+\"rtt2chunkThroughput_natural_limx.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BW with RTT + throughput with DataDelay in one Plot\n",
    "for f in glob.iglob('./*10-*/**/classicBW2throughputEstimate', recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "    df = pd.read_csv(f, delim_whitespace=True, names = ['seconds_offset', 'classicBW', 'chunkThroughput'])\n",
    "    title=f\n",
    "    \n",
    "    df['movingavgBW'] = pd.rolling_mean(df.classicBW, 100)\n",
    "    df['movingavgTP'] = pd.rolling_mean(df.chunkThroughput, 100)\n",
    "    ax1 = df.plot(kind='line', x='seconds_offset', y='movingavgBW', color='r')\n",
    "    fig = df.plot(kind='line', x='seconds_offset', y='movingavgTP', color='b', ax=ax1)\n",
    "    \n",
    "    \n",
    "    #ax1 = df.plot(kind='line', x='seconds_offset', y='classicBW', color='r')\n",
    "    #fig = df.plot(kind='line', x='seconds_offset', y='chunkThroughput', color='b', ax=ax1)\n",
    "\n",
    "    fig.set_xlabel('Playback time (seconds)')\n",
    "    fig.set_ylabel('Mbit/s')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    f = f[:-18]\n",
    "    plt.savefig(f+\"tpEstimate_mvgavg.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampled buffer level comparison of different samplesizes (INIT CHUNK PROBLEM)\n",
    "db5 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_5_p_44_171004-1535_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "db30 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_30_p_44_171004-1546_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "db50 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_50_p_44_171004-1556_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "db100 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_100_p_44_171004-1607_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "dbS = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_p_44_171004-1520_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "\n",
    "x=db5.seconds_offset\n",
    "x2=db100.seconds_offset\n",
    "y1=db5.bufferlevel\n",
    "y2=db30.bufferlevel\n",
    "y3=db50.bufferlevel\n",
    "y4=db100.bufferlevel\n",
    "y5=dbS.bufferlevel\n",
    "\n",
    "plt.plot(x,y1, 'y:')\n",
    "#plt.plot(x,y2, 'g:')\n",
    "plt.plot(x,y3,'b:')\n",
    "#plt.plot(x2,y4,'k:')\n",
    "plt.plot(x, y5, 'r--')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.05,1])\n",
    "axes.set_xlim([-5,605])\n",
    "\n",
    "plt.legend(['5 Samples', '50 Samples', 'Segment'])\n",
    "plt.xlabel('Playback time (seconds)')\n",
    "plt.ylabel('Buffer fill level')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./presentation_figures/presentation_prob-bufferlevel.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampled quality level comparison of different samplesizes (INIT CHUNK PROBLEM)\n",
    "dq5 = pd.read_csv(os.path.join(os.path.dirname(PATH), \"{0}_out\".format(os.path.basename(PATH)), 'quality'), delim_whitespace=True, \n",
    "                     names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "dq30 = pd.read_csv(os.path.join(os.path.dirname(PATH).replace(\"1\", \"2\"), \"{0}_out\".format(os.path.basename(PATH)), \"quality\"), delim_whitespace=True, \n",
    "                     names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "#dq50 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_50_p_44_171004-1556_out/quality', delim_whitespace=True, names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate'])\n",
    "#dq100 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_100_p_44_171004-1607_out/quality', delim_whitespace=True, names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate'])\n",
    "#dqS = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_p_44_171004-1520_out/quality', delim_whitespace=True, names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate'])\n",
    "\n",
    "dq5.videobitrate = dq5.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dq30.videobitrate = dq30.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "#dq50.videobitrate = dq50.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "#dq100.videobitrate = dq100.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "#dqS.videobitrate = dqS.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "x1=dq5.seconds_offset\n",
    "x2=dq30.seconds_offset\n",
    "y1=dq5.videobitrate\n",
    "y2=dq30.videobitrate\n",
    "#y3=dq50.videobitrate\n",
    "#y4=dq100.videobitrate\n",
    "#y5=dqS.videobitrate\n",
    "\n",
    "plt.plot(x1,y1, 'y:')\n",
    "#plt.plot(x,y2, 'g:')\n",
    "plt.plot(x2,y2, 'b:')\n",
    "#plt.plot(x,y4, 'k:')\n",
    "#plt.plot(x,y5, 'r--')\n",
    "\n",
    "#profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "#sec=profile.seconds_offset\n",
    "#bw=profile.bandwidth\n",
    "#plt.plot(sec, bw, '#888888')\n",
    "\n",
    "axes = plt.gca()\n",
    "#axes.set_xlim([-5,600])\n",
    "    \n",
    "#plt.legend(['5 Samples', '30 Samples', '50 Samples', '100 Samples', 'Segment', 'BW Profile'])\n",
    "#plt.legend(['5 Samples', '50 Samples', 'Segment', 'BW Profile'])\n",
    "plt.xlabel('Playback time (seconds)')\n",
    "plt.ylabel('Quality level (Mbit/s)')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/{0}presentation_prob-quality.pdf\".format(os.path.basename(PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for the table\n",
    "print(dq5.videobitrate.mean(), \"\\n\",\n",
    "      dq30.videobitrate.mean(), \"\\n\",\n",
    "      dq50.videobitrate.mean(), \"\\n\",\n",
    "      dq100.videobitrate.mean(), \"\\n\",\n",
    "      dqS.videobitrate.mean(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampled throughput comparison of different samplesizes (INIT CHUNK PROBLEM)\n",
    "dt5 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_5_p_44_171004-1535_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dt30 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_30_p_44_171004-1546_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dt50 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_50_p_44_171004-1556_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dt100 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_100_p_44_171004-1607_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dtS = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_p_44_171004-1520_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "\n",
    "\n",
    "dt5.throughput = dt5.throughput.apply(lambda x: x* 1.00e-6) # in Mbit/s\n",
    "dt30.throughput = dt30.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dt50.throughput = dt50.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dt100.throughput = dt100.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dtS.throughput = dtS.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "x1=dt5.seconds_offset\n",
    "y1=dt5.throughput\n",
    "x2=dt30.seconds_offset\n",
    "y2=dt30.throughput\n",
    "x3=dt50.seconds_offset\n",
    "y3=dt50.throughput\n",
    "x4=dt100.seconds_offset\n",
    "y4=dt100.throughput\n",
    "x5=dtS.seconds_offset\n",
    "y5=dtS.throughput\n",
    "\n",
    "profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "sec=profile.seconds_offset\n",
    "bw=profile.bandwidth\n",
    "plt.plot(sec, bw, '#888888',  linewidth=1.0, zorder=2)\n",
    "\n",
    "plt.scatter(x1,y1,color='y', marker='x', zorder=1)\n",
    "#plt.scatter(x2,y2,color='g', marker='o')\n",
    "plt.scatter(x3,y3,color='b', marker='x', zorder=4)\n",
    "#plt.scatter(x4,y4,color='k', marker='o')\n",
    "plt.scatter(x5,y5,color='r', marker='x', zorder=3)\n",
    "\n",
    "axes = plt.gca()\n",
    "#axes.set_ylim([1,7])\n",
    "axes.set_xlim([-25,600])\n",
    "\n",
    "plt.legend(['BW Profile', '5 Samples', '50 Samples','Segment'])\n",
    "plt.xlabel('Playback time (seconds)')\n",
    "plt.ylabel('Estimated Throughput (Mbit/s)')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./presentation_figures/presentation_prob-throughput.pdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "out = []\n",
    "labels = []\n",
    "lines = []\n",
    "#compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "#             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "#             ('Extended Panda', '2017.12.21-09:04-psequential_log')]\n",
    "\n",
    "compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "             ('Extended Panda', '2017.12.22-14:08-psequential_log')]\n",
    "for alg, file in compPaths:\n",
    "    for i in range(1,3):\n",
    "        ndnChunkTroghput('./NDN/results/client{0}/{1}'.format(i, file), kind='hist')\n",
    "    lines.append(data['./NDN/results/client1'].plot('seconds_offset', ax=ax, kind='hist',   range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True))\n",
    "    lines.append(data['./NDN/results/client2'].plot('seconds_offset', ax=ax, kind='hist',  range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True))\n",
    "    labels.append('{} First Client'.format(alg))\n",
    "    labels.append('{} Second Client'.format(alg))\n",
    "    out.append({alg: data})\n",
    "    #fig = data['./results/client3'].plot('seconds_offset', kind='hist',  range=(0,20), bins=200, normed=1, histtype='step', cumulative=True, label='First Client', ax=fig)\n",
    "    #fig = data['./results/client4'].plot('seconds_offset', kind='hist',  range=(0,20), bins=200, normed=1, histtype='step', cumulative=True, label='First Client', ax=fig)\n",
    "ax.set_ylabel('CDF')\n",
    "ax.set_xlabel('Mbit/s')\n",
    "ax.set_xlim(0, 50)\n",
    "#fig.plot(sec, bw, 'r--')\n",
    "#fig.set_title(os.path.dirname(f))\n",
    "\n",
    "#data.append({'ndnChunkTroghput': {os.path.dirname(f) : df}})\n",
    "fig.tight_layout()\n",
    "handles, oldlabels = ax.get_legend_handles_labels()\n",
    "#ax.legend(handles, labels)\n",
    "ax.legend(handles,labels)\n",
    "#fig.legend({'First Client', 'Second Client'})#,'Third Client', 'Fourth Client'})\n",
    "#plt.savefig(\"{0}_{1}_{2}\".format('./results/cdfcomp',file, \".pdf\"))\n",
    "fig.savefig(\"./NDN/cdfcomp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../NDN/results/client1\n",
      "./../NDN/results/client2\n",
      "./../NDN/results/client1\n",
      "./../NDN/results/client2\n",
      "./../NDN/results/client1\n",
      "./../NDN/results/client2\n"
     ]
    }
   ],
   "source": [
    "profile = read_trace_file_url('./../NDN/report.2010-09-28_1407CEST.log.txt')\n",
    "def ndnChunkData(PATH, data):\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        data.update({os.path.dirname(f) : df})\n",
    "        \n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "#sns.set_style(\"ticks\")\n",
    "#sns.set_context(\"paper\")\n",
    "#sns.despine(left=True, bottom=False)\n",
    "\n",
    "out = []\n",
    "labels = []\n",
    "lines = []\n",
    "#compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "#             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "#             ('Extended Panda', '2017.12.21-09:04-psequential_log')]\n",
    "res1 = []\n",
    "res2 = []\n",
    "res = []\n",
    "compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "             ('Extended Panda', '2017.12.22-14:08-psequential_log')]\n",
    "for alg, file in compPaths:\n",
    "    data = {}\n",
    "    for i in range(1,3):\n",
    "        ndnChunkData('./../NDN/results/client{0}/{1}'.format(i, file), data)\n",
    "    res1.append(pd.Series(data['./../NDN/results/client1'].chunkThroughput, name='{} First Client'.format(alg)))\n",
    "    res2.append(pd.Series(data['./../NDN/results/client2'].chunkThroughput, name='{} Second Client'.format(alg)))\n",
    "#hist_kws=dict(cumulative=True, range=(0,20), histtype='step'),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec241ef6f840e0999ffc9ea6ec58ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gfx/ndn/ndn-cdf-pandabola.pdf\n"
     ]
    }
   ],
   "source": [
    "#NDN Chunk throughput\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "#plt.set_cmap(palettable.tableau.TableauLight_10.get_mpl_colormap())\n",
    "fig, ax = plt.subplots(2,1, sharex=True)\n",
    "size = setupfiguresthin()\n",
    "fig.set_size_inches(size[0], size[1]*2)\n",
    "#latexify(fig_width=3.5, fig_height=3.5)\n",
    "func_amr = lambda t: 1.0 - t\n",
    "i = 0\n",
    "for data in res1:\n",
    "    ecdf = ECDF(data)\n",
    "    ax[0].plot(ecdf.x, ecdf.y, color=COLOR_DEFAULT_TEHSIS.mpl_colors[i], label=data.name)\n",
    "    i = i +1\n",
    "    #data.plot(kind='hist', range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True, ax=ax[0], legend=True, label=data.name,)\n",
    "    #sns.distplot(a=data, axlabel='', norm_hist=True, bins=200, hist=True,   label=data.name, kde=False, rug=True, ax=ax[0])\n",
    "\n",
    "i = 0              \n",
    "for data in res2:\n",
    "    ecdf = ECDF(data)\n",
    "    ax[1].plot(ecdf.x, ecdf.y, label=data.name, linestyle='--', color=COLOR_DEFAULT_TEHSIS.mpl_colors[i])\n",
    "    i = i +1\n",
    "    #data.plot(kind='hist', range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True, ax=ax[1], legend=True, label=data.name)\n",
    "    #sns.distplot(a=data, axlabel='', norm_hist=True, bins=200, hist=True, label=data.name, kde=False, rug=False, ax=ax[1])\n",
    "\n",
    "ax1 = fig.get_axes()[0]\n",
    "ax2 = fig.get_axes()[1]\n",
    "format_axes(ax1)\n",
    "format_axes(ax2)\n",
    "ecdf = ECDF(profile.bitrate)\n",
    "ax1.plot(ecdf.x, ecdf.y, label='Trace', linestyle='dotted', color=COLOR_DEFAULT_TEHSIS.mpl_colors[i])\n",
    "ax2.plot(ecdf.x, ecdf.y,linestyle='dotted', color=COLOR_DEFAULT_TEHSIS.mpl_colors[i])\n",
    "ax2.set_xlabel('Mbit/s')\n",
    "for axel in fig.get_axes():\n",
    "    axel.set_xscale('log')\n",
    "    axel.set_yscale('log')\n",
    "    axel.set_ylim(0.05, 1)\n",
    "    axel.set_xlim(0.1, 10)\n",
    "    #axel.set_ylabel('CDF',labelpad=-4)\n",
    "\n",
    "    axel.set_ylabel('ECDF')\n",
    "fig.tight_layout() \n",
    "fig.subplots_adjust(top=0.85)\n",
    "fig.legend(ncol=2, loc='upper center')\n",
    "fig\n",
    "plt.savefig(getFilename(name='ndn-cdf-pandabola', FOLDER='ndn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/dstohr/Projects/containernet/results/client2/2017.12.12-15:43-psequential_cwindow\", sep=\"\\t\", names=['time', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCW(PATH):\n",
    "    df = pd.read_csv(PATH, names=['time', 'val'])\n",
    "    #from scipy import stats\n",
    "    #df = df[(np.abs(stats.zscore(df)) < 2).all(axis=1)]\n",
    "    df.plot(x='time', y='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,3):\n",
    "    list_of_files = glob.glob('./results/client{0}/*_cwindow'.format(i)) # * means all if need specific format then *.csv\n",
    "    #print (list_of_files)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    PATH = latest_file\n",
    "    print(PATH)\n",
    "\n",
    "    plotCW(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in data:\n",
    "    print(el)\n",
    "    display(data[el].describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('segmentsizes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "segs = pd.read_csv('./segmentsizes.csv', names = ['offset', 'qualitylevel', 'id', 'scale', 'size'])\n",
    "\n",
    "segs.size = segs['size'].apply(lambda x: x *0.0005) # from Kbits/2s to bps\n",
    "\n",
    "fig = segs.boxplot(column='size', by='qualitylevel', showfliers=False, grid=False,)\n",
    "#fig = sns.boxplot(x=\"size\", y=\"qualitylevel\", data=segs, linewidth=2.5, ax=fig)\n",
    "format_axes(fig)\n",
    "#plt.gca().yaxis.grid(True)\n",
    "\n",
    "plt.title('')\n",
    "plt.suptitle('')\n",
    "sns.despine(offset=10, trim=True);\n",
    "plt.xlabel('Quality Layer')\n",
    "plt.ylabel('Segment Video\\nBitrate (Mbit/s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt\n",
    "plt.savefig(\"./seg_variance_boxplot.pdf\")\n",
    "\n",
    "segs.groupby('qualitylevel').var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../NDN/results/client2\n",
      "./../NDN/results/client2\n",
      "./../NDN/results/client1\n",
      "./../NDN/results/client2\n"
     ]
    }
   ],
   "source": [
    "profile = read_trace_file_url('./../NDN/report.2010-09-28_1407CEST.log.txt')\n",
    "def ndnChunkData(PATH, data):\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        data.update({os.path.dirname(f) : df})\n",
    "        \n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "#sns.set_style(\"ticks\")\n",
    "#sns.set_context(\"paper\")\n",
    "#sns.despine(left=True, bottom=False)\n",
    "\n",
    "out = []\n",
    "labels = []\n",
    "lines = []\n",
    "#compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "#             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "#             ('Extended Panda', '2017.12.21-09:04-psequential_log')]\n",
    "res1 = []\n",
    "res2 = []\n",
    "res = []\n",
    "compPaths = [\n",
    "                ('BOLA','2017.12.14-13:36-psequential_log'),\n",
    "\n",
    "            ('BOLA','2017.12.14-13:03-psequential_log'),\n",
    "             ('Panda', '2017.12.14-09:13-bolasequential_log'),\n",
    "        #     ('Extended Panda', '2017.12.13-13:10-psequential_log')\n",
    "            ]\n",
    "for alg, file in compPaths:\n",
    "    data = {}\n",
    "    for i in range(1,3):\n",
    "        ndnChunkData('./../NDN/results/client{0}/{1}'.format(i, file), data)\n",
    "    #res1.append(pd.Series(data['./../NDN/results/client1'].chunkThroughput, name='{} First Client'.format(alg)))\n",
    "    res1.append(pd.Series(data['./../NDN/results/client2'].chunkThroughput, name='{} Second Client'.format(alg)))\n",
    "#hist_kws=dict(cumulative=True, range=(0,20), histtype='step'),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0982229ef726436896a674d0db242462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5a746c6198>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NDN Chunk throughput\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "#plt.set_cmap(palettable.tableau.TableauLight_10.get_mpl_colormap())\n",
    "fig, ax = plt.subplots(1,1, sharex=True)\n",
    "size = setupfiguresthin()\n",
    "i = 0\n",
    "for data in res1:\n",
    "    ecdf = ECDF(data)\n",
    "    ax.plot(ecdf.x, ecdf.y, color=COLOR_DEFAULT_TEHSIS.mpl_colors[i], label=data.name)\n",
    "    i = i +1\n",
    "    #data.plot(kind='hist', range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True, ax=ax[0], legend=True, label=data.name,)\n",
    "    #sns.distplot(a=data, axlabel='', norm_hist=True, bins=200, hist=True,   label=data.name, kde=False, rug=True, ax=ax[0])\n",
    "\n",
    "ax1 = fig.get_axes()[0]\n",
    "format_axes(ax1)\n",
    "ecdf = ECDF(profile.bitrate)\n",
    "#ax1.plot(ecdf.x, ecdf.y, label='Trace', linestyle='dotted', color=COLOR_DEFAULT_TEHSIS.mpl_colors[i])\n",
    "ax1.set_xlim(0,50)\n",
    "fig.tight_layout() \n",
    "fig.subplots_adjust(top=0.85)\n",
    "fig.legend(ncol=2, loc='upper center')\n",
    "#plt.savefig(getFilename(name='ndn-cdf-pandabola', FOLDER='ndn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
