{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832637f9f7354767ae60f21389482392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "#import matplotlib as plt\n",
    "import sys\n",
    "sys.path.append('../../plotting')\n",
    "from plotlib import * \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import glob\n",
    "from math import sqrt\n",
    "SPINE_COLOR = 'gray'\n",
    "PATH = './../NDN/results/client2/2017112709:25:46_log'\n",
    "import os\n",
    "script = \"./../NDN/Extract_KPIs.sh\"\n",
    "data = {}\n",
    "from palettable.colorbrewer.qualitative import Dark2_7 as colors\n",
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trace_file_url(trace_file_url):\n",
    "    colnames = ['Timestamp','Increasingtime','GPS_1','GPS_2', 'bytes', 'elapsed_ms']\n",
    "    data = pd.read_csv(trace_file_url, names=colnames, delim_whitespace=True)\n",
    "    data['bitrate'] = data.bytes * 8 /  (data.elapsed_ms * 1000 )# mbit/s\n",
    "    data['Increasingtime'] = (data['Increasingtime'] - data['Increasingtime'][0]) / 1000 - 288\n",
    "    data.Timestamp = pd.to_datetime(data.Timestamp)\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Video Segment/Sampled throughput\n",
    "def sampletroughput(PATH, kind='other'):\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        path = os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)),  \"throughput\")\n",
    "        print(path)\n",
    "        df = pd.read_csv(path, delim_whitespace=True ,names = ['seconds_offset', 'throughput'])\n",
    "        df.throughput = df.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        title=f\n",
    "\n",
    "        profile = read_trace_file_url('./NDN/report.2010-09-28_1407CEST.log.txt')\n",
    "        sec=profile.Timestamp\n",
    "        bw=profile.bitrate\n",
    "        if kind == 'cdf':\n",
    "            fig = df.plot(\"throughput\", kind='hist',  bins=200, normed=1, histtype='step',\n",
    "                           cumulative=True)\n",
    "            fig.set_ylabel('Density')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "            #fig.set_xlim(0, 5)\n",
    "        else:\n",
    "            fig = df.plot(x=\"seconds_offset\", y=\"throughput\", kind='scatter', s=0.01)\n",
    "            fig.set_xlabel('Playback time (seconds)')\n",
    "            lines = fig.set_ylabel('Mbit/s')\n",
    "\n",
    "        fig.plot(sec, bw, 'r--')\n",
    "\n",
    "        fig.set_title(os.path.dirname(f))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{0}_throughput{1}\".format(f, \".pdf\"))\n",
    "\n",
    "#sampletroughput(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NDN Chunk throughput\n",
    "\n",
    "def ndnChunkTroghput(PATH, kind='dots'):\n",
    "    N = 5\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        print(f)\n",
    "        #global df\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        title=f\n",
    "\n",
    "        #profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "        #sec=profile.seconds_offset\n",
    "        #bw=profile.bandwidth\n",
    "\n",
    "        #x=df.seconds_offset\n",
    "        #y=df.chunkThroughput\n",
    "        #plt.hexbin(x, y, gridsize=(600,1000), yscale='log', mincnt = 1)\n",
    "        #plt.tight_layout()\n",
    "        #plt.savefig(f+\"_kde_grid_logy.pdf\")\n",
    "        if kind == 'scatter':\n",
    "            fig = df.plot(x=\"seconds_offset\" , y=\"chunkThroughput\", logy=False, kind='scatter', marker='x', s=0.05)\n",
    "            fig.set_xlabel('Playback time (seconds)')\n",
    "            fig.set_ylim(0,6)\n",
    "            fig.set_xlim(0,200)\n",
    "            fig.set_ylabel('Mbit/s')\n",
    "        elif kind == 'hist':\n",
    "            fig = df.plot(x=\"seconds_offset\" , y=\"chunkThroughput\", kind='hist', bins=50)\n",
    "            fig.set_ylabel('???')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "        elif kind == 'kde':\n",
    "            fig = df.plot(\"chunkThroughput\", kind='kde')\n",
    "            fig.set_ylabel('Density')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "            fig.set_xlim(0, 100)\n",
    "        elif kind == 'cdf':\n",
    "            fig = df.plot(\"seconds_offset\", kind='hist',  bins=200, normed=1, histtype='step',\n",
    "                           cumulative=True)\n",
    "            fig.set_ylabel('Density')\n",
    "            fig.set_xlabel('Mbit/s')\n",
    "            fig.set_xlim(0, 10)\n",
    "            \n",
    "        #profile = read_trace_file_url('./ndn/report.2010-09-28_1407CEST.log.txt')\n",
    "        #sec=profile['Increasingtime']\n",
    "        #bw=profile.bitrate\n",
    "        #profile\n",
    "        #fig.plot(sec, bw, colors.mpl_colors[0])\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        fig.legend({'NDN-Chunk based measurment', 'Bandwidth trace'})\n",
    "\n",
    "\n",
    "\n",
    "        data.update({os.path.dirname(f) : df})\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{0}_scatter_natural_logy-{1}{2}\".format(f,os.path.dirname(f).split('/')[2], \".pdf\"))\n",
    "        \n",
    "        \n",
    "#NDN Chunk throughput\n",
    "\n",
    "def ndnChunkTroghputQuality(PATH):\n",
    "    N = 5\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        print(f)\n",
    "        #global df\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        title=f\n",
    "\n",
    "        #profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "        #sec=profile.seconds_offset\n",
    "        #bw=profile.bandwidth\n",
    "\n",
    "        #x=df.seconds_offset\n",
    "        #y=df.chunkThroughput\n",
    "        #plt.hexbin(x, y, gridsize=(600,1000), yscale='log', mincnt = 1)\n",
    "        #plt.tight_layout()\n",
    "        #plt.savefig(f+\"_kde_grid_logy.pdf\")\n",
    "        fig = df.plot(x=\"seconds_offset\" , y=\"chunkThroughput\", logy=False, label='NDN-Chunk Troughput', kind='scatter', c='0.4', marker='x', s=0.08)\n",
    "        fig.set_xlabel('Playback time (seconds)')\n",
    "        fig.set_ylim(0,6)\n",
    "        fig.set_xlim(0,200)\n",
    "        fig.set_ylabel('Mbit/s')\n",
    "            \n",
    "        profile = read_trace_file_url('./ndn/report.2010-09-28_1407CEST.log.txt')\n",
    "        sec=profile['Increasingtime']\n",
    "        bw=profile.bitrate\n",
    "        profile\n",
    "        bw_plot = fig.plot(sec, bw, label='Bandwidth Trace')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"quality\") , delim_whitespace=True, \n",
    "                         names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "\n",
    "        df.videobitrate = df.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        df.realbitrate = df.realbitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "\n",
    "        bitrate_plot = fig.plot(df.seconds_offset, df.videobitrate, 'r', label='Video Bitrate')\n",
    "        \n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        #fig.legend([bw_plot, bitrate_plot], ['Video Bitrate',  'Bandwidth trace'])\n",
    "        handles, labels = fig.get_legend_handles_labels()\n",
    "        # sort both labels and handles by labels\n",
    "        labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "        fig.legend(handles, labels)\n",
    "        fig.legend(handles, labels, ncol=3,  loc='upper center', frameon=True, mode=\"expand\")\n",
    "        data.update({os.path.dirname(f) : df})\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{0}_scatter_natural_logy-{1}{2}\".format(f,os.path.dirname(f).split('/')[2].strip('.'), \".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qualityPlot(PATH):\n",
    "    #Quality levels\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"quality\") , delim_whitespace=True, \n",
    "                         names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "        title=f\n",
    "        df.videobitrate = df.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "        df.realbitrate = df.realbitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "        #profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "        #sec=profile.seconds_offset\n",
    "        #bw=profile.bandwidth\n",
    "\n",
    "        fig = df.plot(x=\"seconds_offset\", y=\"realbitrate\", )\n",
    "\n",
    "       # fig.plot([1, 600], [1.03, 1.03], 'y:') \n",
    "       # fig.plot([1, 600], [1.24, 1.24], 'y:')\n",
    "       # fig.plot([1, 600], [1.55, 1.55], 'y:')\n",
    "       # fig.plot([1, 600], [2.13, 2.13], 'y:')\n",
    "       # fig.plot([1, 600], [2.48, 2.48], 'y:')\n",
    "       # fig.plot([1, 600], [3.08, 3.08], 'y:')\n",
    "       # fig.plot([1, 600], [3.53, 3.53], 'y:')\n",
    "       # fig.plot([1, 600], [3.84, 3.84], 'y:')\n",
    "       # fig.plot([1, 600], [4.22, 4.22], 'y:')\n",
    "\n",
    "        br = fig.plot(df.seconds_offset, df.videobitrate, 'r:', label='Selected Adaptation Bitrate')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"bufferlevel\") , delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "        df.bufferlevel = df.bufferlevel.apply(lambda x: x * 1.00e+2) # in Percentage\n",
    "        #title=f\n",
    "        bl = fig.plot(df.seconds_offset, df.bufferlevel, 'k--', label='Real Segment Bitrate')\n",
    "\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        #fig.plot(sec, bw, 'k--')\n",
    "\n",
    "        print(df.videobitrate.mean())\n",
    "\n",
    "        fig.set_xlabel('Playback time (seconds)')\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "        handles, labels = fig.get_legend_handles_labels()\n",
    "        # sort both labels and handles by labels\n",
    "        labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "        fig.legend(handles, labels, bbox_to_anchor=(0., 1.02, 1., .102), loc=1, ncol=1, mode=\"expand\", borderaxespad=0.)\n",
    "        #fig.legend([br, bl], ['Real Segment Bitrate', 'Selected Adaptation Bitrate'])\n",
    "        #, 'Buffer fill level (percentage)'})\n",
    "\n",
    "        lines = fig.set_ylabel('Video quality (Mbit/s)')\n",
    "        #plt.tight_layout()\n",
    "        plt.savefig(\"{0}_quality-{1}{2}\".format(f,os.path.dirname(f).split('/')[2].strip('.'), \".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bufferPlot(PATH):\n",
    "    #Buffer fill level\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"bufferlevel\") , delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "        df.bufferlevel = df.bufferlevel.apply(lambda x: x * 1.00e+2) # in Percentage\n",
    "        title=f\n",
    "        fig = df.plot(x=\"seconds_offset\", y=\"bufferlevel\", )\n",
    "        fig.set_xlabel('Playback time (seconds)')\n",
    "        lines = fig.set_ylabel('Buffer fill level (percentage)')\n",
    "        plt.tight_layout()\n",
    "        fig.legend({})\n",
    "        #fig.set_title(os.path.dirname(f))\n",
    "\n",
    "        plt.savefig(\"{0}_bufferlevel-{1}{2}\".format(f,os.path.dirname(f).split('/')[2].strip('.'), \".pdf\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "for i in range(1,3):\n",
    "    list_of_files = glob.glob('./NDN/results/client{0}/2017.12.21*_log'.format(i)) # * means all if need specific format then *.csv\n",
    "    latest_file = sorted(list_of_files, key=os.path.getctime)[1]\n",
    "    print(latest_file)\n",
    "    PATH = latest_file\n",
    "    print(PATH)\n",
    "\n",
    "    #sampletroughput(PATH, kind='scatter')\n",
    "    ndnChunkTroghput(PATH, kind='hist')\n",
    "    #ndnChunkTroghputQuality(PATH)\n",
    "    #qualityPlot(PATH)\n",
    "    #bufferPlot(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#gOut/gIn and Chunk Throughput\n",
    "for f in glob.iglob('./*10-*/**/chunkThroughputRttQuotient', recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "    df = pd.read_csv(f, delim_whitespace=True, names = ['seconds_offset', 'rtt', 'quotient', 'chunkThroughput'])\n",
    "\n",
    "    \n",
    "    #df['movingavgTP'] = pd.rolling_mean(df.chunkThroughput, 100)\n",
    "    #df['movingavgQ'] = pd.rolling_mean(df.quotient, 100)\n",
    "    #fig = df.plot.scatter(x=\"movingavgTP\", y=\"movingavgQ\", s=0.001)\n",
    "    fig = df.plot.scatter(x=\"chunkThroughput\", y=\"quotient\", s=0.001)\n",
    "    \n",
    "    #fig.set_xscale('log')\n",
    "    #fig.set_yscale('log')\n",
    "    fig.set_xbound(0,10)\n",
    "    fig.set_ybound(0,3)\n",
    "    \n",
    "    fig.set_xlabel('Throughput (Mbit/s)')\n",
    "    fig.set_ylabel('gOut/gIn')\n",
    "    plt.tight_layout()\n",
    "    f = f[:-26]\n",
    "    plt.savefig(f+\"gOutgIn2chunkThroughput_natural_limxlimy3.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RTT and Chunk Throughput\n",
    "for f in glob.iglob('./*10-*/**/chunkThroughputRttQuotient', recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "    df = pd.read_csv(f, delim_whitespace=True, names = ['seconds_offset', 'rtt', 'quotient', 'chunkThroughput'])\n",
    "    df.rtt = df.rtt.apply(lambda x: x * 1.00e-3) # in ms\n",
    "    \n",
    "    #df['movingavgTP'] = pd.rolling_mean(df.chunkThroughput, 100)\n",
    "    #df['movingavgRTT'] = pd.rolling_mean(df.rtt, 100)\n",
    "    #fig = df.plot.scatter(x=\"movingavgTP\", y=\"movingavgRTT\", s=0.001)\n",
    "    fig = df.plot.scatter(x=\"chunkThroughput\", y=\"rtt\", s=0.001)\n",
    "    \n",
    "    #fig.set_xscale('log')\n",
    "    #fig.set_yscale('log')\n",
    "    fig.set_xbound(0,10)\n",
    "    \n",
    "    fig.set_xlabel('Throughput (Mbit/s)')\n",
    "    fig.set_ylabel('RTT (ms)')\n",
    "    plt.tight_layout()\n",
    "    f = f[:-26]\n",
    "    plt.savefig(f+\"rtt2chunkThroughput_natural_limx.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BW with RTT + throughput with DataDelay in one Plot\n",
    "for f in glob.iglob('./*10-*/**/classicBW2throughputEstimate', recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "    df = pd.read_csv(f, delim_whitespace=True, names = ['seconds_offset', 'classicBW', 'chunkThroughput'])\n",
    "    title=f\n",
    "    \n",
    "    df['movingavgBW'] = pd.rolling_mean(df.classicBW, 100)\n",
    "    df['movingavgTP'] = pd.rolling_mean(df.chunkThroughput, 100)\n",
    "    ax1 = df.plot(kind='line', x='seconds_offset', y='movingavgBW', color='r')\n",
    "    fig = df.plot(kind='line', x='seconds_offset', y='movingavgTP', color='b', ax=ax1)\n",
    "    \n",
    "    \n",
    "    #ax1 = df.plot(kind='line', x='seconds_offset', y='classicBW', color='r')\n",
    "    #fig = df.plot(kind='line', x='seconds_offset', y='chunkThroughput', color='b', ax=ax1)\n",
    "\n",
    "    fig.set_xlabel('Playback time (seconds)')\n",
    "    fig.set_ylabel('Mbit/s')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    f = f[:-18]\n",
    "    plt.savefig(f+\"tpEstimate_mvgavg.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampled buffer level comparison of different samplesizes (INIT CHUNK PROBLEM)\n",
    "db5 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_5_p_44_171004-1535_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "db30 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_30_p_44_171004-1546_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "db50 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_50_p_44_171004-1556_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "db100 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_100_p_44_171004-1607_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "dbS = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_p_44_171004-1520_out/bufferlevel', delim_whitespace=True, names = ['seconds_offset', 'bufferlevel'])\n",
    "\n",
    "x=db5.seconds_offset\n",
    "x2=db100.seconds_offset\n",
    "y1=db5.bufferlevel\n",
    "y2=db30.bufferlevel\n",
    "y3=db50.bufferlevel\n",
    "y4=db100.bufferlevel\n",
    "y5=dbS.bufferlevel\n",
    "\n",
    "plt.plot(x,y1, 'y:')\n",
    "#plt.plot(x,y2, 'g:')\n",
    "plt.plot(x,y3,'b:')\n",
    "#plt.plot(x2,y4,'k:')\n",
    "plt.plot(x, y5, 'r--')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.05,1])\n",
    "axes.set_xlim([-5,605])\n",
    "\n",
    "plt.legend(['5 Samples', '50 Samples', 'Segment'])\n",
    "plt.xlabel('Playback time (seconds)')\n",
    "plt.ylabel('Buffer fill level')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./presentation_figures/presentation_prob-bufferlevel.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampled quality level comparison of different samplesizes (INIT CHUNK PROBLEM)\n",
    "dq5 = pd.read_csv(os.path.join(os.path.dirname(PATH), \"{0}_out\".format(os.path.basename(PATH)), 'quality'), delim_whitespace=True, \n",
    "                     names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "dq30 = pd.read_csv(os.path.join(os.path.dirname(PATH).replace(\"1\", \"2\"), \"{0}_out\".format(os.path.basename(PATH)), \"quality\"), delim_whitespace=True, \n",
    "                     names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate', 'useless', 'realbitrate'])\n",
    "#dq50 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_50_p_44_171004-1556_out/quality', delim_whitespace=True, names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate'])\n",
    "#dq100 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_100_p_44_171004-1607_out/quality', delim_whitespace=True, names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate'])\n",
    "#dqS = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_p_44_171004-1520_out/quality', delim_whitespace=True, names = ['seconds_offset', 'useless', 'useless', 'segment_number', 'qualitylevel', 'videobitrate'])\n",
    "\n",
    "dq5.videobitrate = dq5.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dq30.videobitrate = dq30.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "#dq50.videobitrate = dq50.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "#dq100.videobitrate = dq100.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "#dqS.videobitrate = dqS.videobitrate.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "x1=dq5.seconds_offset\n",
    "x2=dq30.seconds_offset\n",
    "y1=dq5.videobitrate\n",
    "y2=dq30.videobitrate\n",
    "#y3=dq50.videobitrate\n",
    "#y4=dq100.videobitrate\n",
    "#y5=dqS.videobitrate\n",
    "\n",
    "plt.plot(x1,y1, 'y:')\n",
    "#plt.plot(x,y2, 'g:')\n",
    "plt.plot(x2,y2, 'b:')\n",
    "#plt.plot(x,y4, 'k:')\n",
    "#plt.plot(x,y5, 'r--')\n",
    "\n",
    "#profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "#sec=profile.seconds_offset\n",
    "#bw=profile.bandwidth\n",
    "#plt.plot(sec, bw, '#888888')\n",
    "\n",
    "axes = plt.gca()\n",
    "#axes.set_xlim([-5,600])\n",
    "    \n",
    "#plt.legend(['5 Samples', '30 Samples', '50 Samples', '100 Samples', 'Segment', 'BW Profile'])\n",
    "#plt.legend(['5 Samples', '50 Samples', 'Segment', 'BW Profile'])\n",
    "plt.xlabel('Playback time (seconds)')\n",
    "plt.ylabel('Quality level (Mbit/s)')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/{0}presentation_prob-quality.pdf\".format(os.path.basename(PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for the table\n",
    "print(dq5.videobitrate.mean(), \"\\n\",\n",
    "      dq30.videobitrate.mean(), \"\\n\",\n",
    "      dq50.videobitrate.mean(), \"\\n\",\n",
    "      dq100.videobitrate.mean(), \"\\n\",\n",
    "      dqS.videobitrate.mean(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampled throughput comparison of different samplesizes (INIT CHUNK PROBLEM)\n",
    "dt5 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_5_p_44_171004-1535_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dt30 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_30_p_44_171004-1546_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dt50 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_50_p_44_171004-1556_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dt100 = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_c_100_p_44_171004-1607_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "dtS = pd.read_csv('./results_10-04_WITH-initChunk-used/logNDN_p_44_171004-1520_out/throughput', delim_whitespace=True, names = ['seconds_offset', 'throughput'])\n",
    "\n",
    "\n",
    "dt5.throughput = dt5.throughput.apply(lambda x: x* 1.00e-6) # in Mbit/s\n",
    "dt30.throughput = dt30.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dt50.throughput = dt50.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dt100.throughput = dt100.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "dtS.throughput = dtS.throughput.apply(lambda x: x * 1.00e-6) # in Mbit/s\n",
    "\n",
    "x1=dt5.seconds_offset\n",
    "y1=dt5.throughput\n",
    "x2=dt30.seconds_offset\n",
    "y2=dt30.throughput\n",
    "x3=dt50.seconds_offset\n",
    "y3=dt50.throughput\n",
    "x4=dt100.seconds_offset\n",
    "y4=dt100.throughput\n",
    "x5=dtS.seconds_offset\n",
    "y5=dtS.throughput\n",
    "\n",
    "profile = pd.read_csv('./StandardDASH_Profile', delim_whitespace=True, names = ['seconds_offset', 'bandwidth', 'latency' ])\n",
    "sec=profile.seconds_offset\n",
    "bw=profile.bandwidth\n",
    "plt.plot(sec, bw, '#888888',  linewidth=1.0, zorder=2)\n",
    "\n",
    "plt.scatter(x1,y1,color='y', marker='x', zorder=1)\n",
    "#plt.scatter(x2,y2,color='g', marker='o')\n",
    "plt.scatter(x3,y3,color='b', marker='x', zorder=4)\n",
    "#plt.scatter(x4,y4,color='k', marker='o')\n",
    "plt.scatter(x5,y5,color='r', marker='x', zorder=3)\n",
    "\n",
    "axes = plt.gca()\n",
    "#axes.set_ylim([1,7])\n",
    "axes.set_xlim([-25,600])\n",
    "\n",
    "plt.legend(['BW Profile', '5 Samples', '50 Samples','Segment'])\n",
    "plt.xlabel('Playback time (seconds)')\n",
    "plt.ylabel('Estimated Throughput (Mbit/s)')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./presentation_figures/presentation_prob-throughput.pdf\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "out = []\n",
    "labels = []\n",
    "lines = []\n",
    "#compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "#             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "#             ('Extended Panda', '2017.12.21-09:04-psequential_log')]\n",
    "\n",
    "compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "             ('Extended Panda', '2017.12.22-14:08-psequential_log')]\n",
    "for alg, file in compPaths:\n",
    "    for i in range(1,3):\n",
    "        ndnChunkTroghput('./NDN/results/client{0}/{1}'.format(i, file), kind='hist')\n",
    "    lines.append(data['./NDN/results/client1'].plot('seconds_offset', ax=ax, kind='hist',   range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True))\n",
    "    lines.append(data['./NDN/results/client2'].plot('seconds_offset', ax=ax, kind='hist',  range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True))\n",
    "    labels.append('{} First Client'.format(alg))\n",
    "    labels.append('{} Second Client'.format(alg))\n",
    "    out.append({alg: data})\n",
    "    #fig = data['./results/client3'].plot('seconds_offset', kind='hist',  range=(0,20), bins=200, normed=1, histtype='step', cumulative=True, label='First Client', ax=fig)\n",
    "    #fig = data['./results/client4'].plot('seconds_offset', kind='hist',  range=(0,20), bins=200, normed=1, histtype='step', cumulative=True, label='First Client', ax=fig)\n",
    "ax.set_ylabel('CDF')\n",
    "ax.set_xlabel('Mbit/s')\n",
    "ax.set_xlim(0, 50)\n",
    "#fig.plot(sec, bw, 'r--')\n",
    "#fig.set_title(os.path.dirname(f))\n",
    "\n",
    "#data.append({'ndnChunkTroghput': {os.path.dirname(f) : df}})\n",
    "fig.tight_layout()\n",
    "handles, oldlabels = ax.get_legend_handles_labels()\n",
    "#ax.legend(handles, labels)\n",
    "ax.legend(handles,labels)\n",
    "#fig.legend({'First Client', 'Second Client'})#,'Third Client', 'Fourth Client'})\n",
    "#plt.savefig(\"{0}_{1}_{2}\".format('./results/cdfcomp',file, \".pdf\"))\n",
    "fig.savefig(\"./NDN/cdfcomp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../NDN/results/client1\n",
      "./../NDN/results/client2\n",
      "./../NDN/results/client1\n",
      "./../NDN/results/client2\n",
      "./../NDN/results/client1\n",
      "./../NDN/results/client2\n"
     ]
    }
   ],
   "source": [
    "profile = read_trace_file_url('./../NDN/report.2010-09-28_1407CEST.log.txt')\n",
    "def ndnChunkData(PATH, data):\n",
    "    for f in glob.iglob(PATH, recursive=True): # /*directoryRegExp*/ to reduce output (long runtime)\n",
    "        ! {script} {os.path.dirname(f)} {os.path.basename(f)}\n",
    "        df = pd.read_csv(os.path.join(os.path.dirname(f), \"{0}_out\".format(os.path.basename(f)), \"chunkThroughput\") , delim_whitespace=True ,names = ['seconds_offset', 'chunkThroughput'])\n",
    "        data.update({os.path.dirname(f) : df})\n",
    "        \n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "#sns.set_style(\"ticks\")\n",
    "#sns.set_context(\"paper\")\n",
    "#sns.despine(left=True, bottom=False)\n",
    "\n",
    "out = []\n",
    "labels = []\n",
    "lines = []\n",
    "#compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "#             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "#             ('Extended Panda', '2017.12.21-09:04-psequential_log')]\n",
    "res1 = []\n",
    "res2 = []\n",
    "res = []\n",
    "compPaths = [('BOLA','2017.12.22-14:41-bolasequential_log'),\n",
    "             ('Panda', '2017.12.21-11:15-pandasequential_log'),\n",
    "             ('Extended Panda', '2017.12.22-14:08-psequential_log')]\n",
    "for alg, file in compPaths:\n",
    "    data = {}\n",
    "    for i in range(1,3):\n",
    "        ndnChunkData('./../NDN/results/client{0}/{1}'.format(i, file), data)\n",
    "    res1.append(pd.Series(data['./../NDN/results/client1'].chunkThroughput, name='{} First Client'.format(alg)))\n",
    "    res2.append(pd.Series(data['./../NDN/results/client2'].chunkThroughput, name='{} Second Client'.format(alg)))\n",
    "#hist_kws=dict(cumulative=True, range=(0,20), histtype='step'),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ced83847449401aaa40291506c81fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NDN Chunk throughput\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "fig, ax = plt.subplots(2,1, sharex=True)\n",
    "latexify()\n",
    "fig.set_size_inches(3.5, 5)\n",
    "#latexify(fig_width=3.5, fig_height=3.5)\n",
    "func_amr = lambda t: 1.0 - t\n",
    "\n",
    "for data in res1:\n",
    "    ecdf = ECDF(data)\n",
    "    ax[0].plot(ecdf.x, np.vectorize(func_amr)(ecdf.y), label=data.name)\n",
    "    #data.plot(kind='hist', range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True, ax=ax[0], legend=True, label=data.name,)\n",
    "    #sns.distplot(a=data, axlabel='', norm_hist=True, bins=200, hist=True,   label=data.name, kde=False, rug=True, ax=ax[0])\n",
    "              \n",
    "for data in res2:\n",
    "    ecdf = ECDF(data)\n",
    "    ax[1].plot(ecdf.x, np.vectorize(func_amr)(ecdf.y), label=data.name)\n",
    "    #data.plot(kind='hist', range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True, ax=ax[1], legend=True, label=data.name)\n",
    "    #sns.distplot(a=data, axlabel='', norm_hist=True, bins=200, hist=True, label=data.name, kde=False, rug=False, ax=ax[1])\n",
    "\n",
    "for axel in ax:\n",
    "    ecdf = ECDF(profile.bitrate)\n",
    "    axel.plot(ecdf.x, np.vectorize(func_amr)(ecdf.y), label='Trace')\n",
    "    axel.set_xscale('log')\n",
    "    axel.set_yscale('log')\n",
    "    axel.legend(loc=\"lower left\")\n",
    "    axel.set_ylim(0.05, 1)\n",
    "    axel.set_xlim(0.1, 15)\n",
    "    axel.set_ylabel('CDF',labelpad=-4)\n",
    "    #ax.plot(kind='hist', range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True, ax=ax[1], legend=True, label='Trace')\n",
    "    #profile.bitrate.plot(kind='hist', range=(0,50), bins=1000, normed=1, histtype='step', cumulative=True, ax=ax[0], legend=True, label='Trace')\n",
    "\n",
    "#fig.set_ylabel('CDF')\n",
    "ax[1].set_xlabel('Mbit/s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./../NDN/cdfcomp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/dstohr/Projects/containernet/results/client2/2017.12.12-15:43-psequential_cwindow\", sep=\"\\t\", names=['time', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCW(PATH):\n",
    "    df = pd.read_csv(PATH, names=['time', 'val'])\n",
    "    #from scipy import stats\n",
    "    #df = df[(np.abs(stats.zscore(df)) < 2).all(axis=1)]\n",
    "    df.plot(x='time', y='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,3):\n",
    "    list_of_files = glob.glob('./results/client{0}/*_cwindow'.format(i)) # * means all if need specific format then *.csv\n",
    "    #print (list_of_files)\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    PATH = latest_file\n",
    "    print(PATH)\n",
    "\n",
    "    plotCW(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in data:\n",
    "    print(el)\n",
    "    display(data[el].describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
